[
{
	"uri": "//localhost:1313/vi/6-devsecops/6.1-ops-repo/",
	"title": "Cấu hình GitHub Repository (Ops Repo)",
	"tags": [],
	"description": "",
	"content": "Thiết lập Webhook Tại phần Settings -\u0026gt; Webhooks ở Ops Repository, chọn phần \u0026lsquo;Add Webhooks’ với setting ở bên dưới:\nViết Jenkinsfile Bài Workshop này sẽ không hướng dẫn viết Jenkinsfile, bạn đọc tham khảo tại Ops Repo.\n"
},
{
	"uri": "//localhost:1313/vi/7-argocd-autodeploy/7.1-ci-pipeline/",
	"title": "Chạy CI Pipeline",
	"tags": [],
	"description": "",
	"content": "Trigger CI Pipeline Ở Dev Repository, đẩy code lên Github Repository để trigger Jenkins Pipeline:\nQuay trở về Jenkins Server, bạn đọc có thể thấy tổng cộng có 3 pipeline đang chạy.\nSau một lúc, CI Pipeline đã chạy hoàn thành như bên dưới:\nKiểm tra Image ở Private Registry Ở remote Dev Repository, ta thấy lần cuối một commit được đẩy lên có ID d966430 như bên dưới:\nKiểm tra ở AWS Elastic Container Registry, bạn đọc sẽ thấy ta có tổng cộng 3 Image được tagged theo commit ID:\nBây giờ, ta đã sẵn sàng dùng Argo CD để triển khai Automation Deployment.\n"
},
{
	"uri": "//localhost:1313/vi/1-introduce/",
	"title": "Đặt vấn đề",
	"tags": [],
	"description": "",
	"content": "Tại sao là Microservices? Trước khi tìm hiểu về Microservices, ta cần tìm hiểu về cách triển khai production truyền thống: Monolithic. Monolithic là cách ‘đóng gói’ (hay còn gọi là containerize) phần mềm thành một khối duy nhất và triển khai nó lên server. Công nghệ containerize phổ biến mà bạn đọc có thể nghe đến tiêu biểu là Docker. Tưởng tượng phần mềm của bạn được containerized thành một khối duy nhất (hay còn gọi là Image) và đã được triển khai lên server. Bây giờ, một tính năng mới đã được phát triển và sẵn sàng triển khai trên môi trường production. Quá trình update phần mềm sẽ được diễn ra như hình bên dưới.\nNhư bạn đọc có thể thấy, application bắt buộc phải bị tắt, sau đó, phiên bản mới nhất sẽ được khởi chạy. Lúc này đồng nghĩa với việc End User sẽ phải đối diện với downtime vì rõ ràng, phần mềm được ‘đóng gói’ thành một khối duy nhất và việc update một chức năng cũ lại ảnh hưởng cả tập thể. Tất nhiên, vấn đề này có thể giải quyết bằng các Deployment Strategy như Blue/Green Deployment, etc.\nTuy nhiên, có một kiến trúc phần mềm có thể giải quyết bài toán này: Microservices. Nôm na, Microservices là chia các chức năng (Service) trong Application thành các khối khác nhau và chúng giao tiếp với nhau thông qua các chuẩn giao tiếp như REST, v.v. Việc cập nhật một service sẽ không ảnh hưởng đến các service khác như hình bên dưới.\nTriển khai một ứng dụng Microservice trên Kubernetes (K8s) là một bài toán tiêu biểu. Lúc này ta cần triển khai hạ tầng, và cấu hình cho cụm K8s đòi hỏi sự hợp tác của Team Vận hành (hay Ops Team bao gồm các system engineer, system administrator, network engineer, etc). Và GitOps sẽ là câu trả lời để đảm bảo sự phối hợp đó.\nTại sao là GitOps? Tại sao là DevSecOps? DevOps đã tối ưu hoá quy trình phát triển phần mềm bằng việc ứng dụng các công cụ automation và làm giảm thiểu thời gian ‘release’ sản phẩm. Từ đó, end users và đội ngũ phát triển sẽ được lợi, khi đó:\nEnd user sẽ được cập nhật phiên bản mới nhất của sản phẩm một cách nhanh chóng Đội ngũ phát triển sẽ tập trung vào công việc phát triển phần mềm, khi những công đoạn thủ công như: kiểm thử, containerize, etc. đã được tự động hoá. Tuy nhiên, trong quá trình automation đó, liệu ta có muốn kiểm thử những lỗ hổng bảo mật của source code, built image, hay chính production của chúng ta một cách tự động? Và thế là DevSecOps ra đời để giải quyết những bài toán đó. Trong khuôn khổ của bài Workshop này, chúng ta sẽ triển khai các phương pháp kiểm thử trong DevSecOps như:\nSAST (Static Application Security Testing): thực hiện kiểm thử source code trước khi ‘release’. Ví dụ, nếu ứng dụng của bạn được viết bằng Python, ta sẽ kiểm thử các lỗ hổng bảo mật có thể xuất hiện trên Source Code Python của ta.\nImage Scan và Secure IaC: Tương tự như scan source code cho application, ta cũng sẽ thực hiện scan source code cho hạ tầng (Ví dụ: Liệu hạ tầng cloud của ta có cho phép public access không?) và built image (ví dụ: Image Base của ta có outdated không?).\nDAST (Dynamic Application Security Testing): thực hiện kiểm thử production của chúng ta (Ví dụ: Khi end user gửi một request đến production, liệu có những response không mong muốn nào được trả về không?)\nMonitoring có cần thiết không? Tưởng tượng bạn đọc là một thành viên trong team Dev và Application của chúng ta được triển khai trên cụm Kubernetes. Một khi có lỗi xảy ra ở Application, bạn phải biết cách truy cập vào cụm K8s để xem logs và debug. Nhưng rõ ràng, ta không muốn điều đó xảy ra tí nào vì K8s rất phức tạp, và thế ta cần centralized các logs tại một nơi và developer có thể dễ dàng truy cập cho việc debug. Với bài Workshop này, ta sẽ ứng dụng EFK Stack. Khi đó, Developers sẽ biết được logs thông qua Web Browser.\nTrong bài Workshop này, chúng ta sẽ tận dụng các dịch vụ từ AWS để giải quyết bài toán trên:\nElastic Compute Service (EC2): Nơi ta sẽ host Jenkins Server, SonarQube Server. Chúng là một phần quan trọng trong CI/CD Pipeline của ta Elastic Kubernetes Service (EKS): Thay vì tự tay setup một Kubernetes Cluster, chúng ta sẽ sử dụng dịch vụ từ AWS. Elastic Container Registry (ECR): Đóng vai trò như một \u0026ldquo;Private Docker Hub\u0026rdquo;. Rõ ràng, ta không muốn các Application Image bị lộ. Vì vậy, ta cần một nơi đủ tin cậy để chứa chúng và ECR là giải pháp. Bạn đọc cần cài đặt Terraform trước khi có thể hoàn thành bài Workshop này\n"
},
{
	"uri": "//localhost:1313/vi/5-finish-monitoring/5.1-prome-grafana/",
	"title": "Set up Prometheus và Grafana",
	"tags": [],
	"description": "",
	"content": "Đăng nhập vào Grafana Truy cập DNS của Grafana, bạn đọc đăng nhập với tài khoàn và mật khẩu như bên dưới:\nKế đến, bạn đọc thay đổi mật khẩu theo yêu cầu của Grafana\nTạo Data Source Chọn phần Connections \u0026gt; Data Sources như bên dưới để tạo data source:\nLựa chọn Prometheus làm Data Source như bên dưới:\nPrometheus Server URL sẽ là: http://prometheus-operator-kube-p-prometheus.monitoring.svc.cluster.local:9090\nTạo Dashboard Tại phần Home \u0026gt; Dashboards \u0026gt; Import Dashboard, tạo Dashboard với cấu hình như bên dưới:\nChọn Data Source là Prometheus như bên dưới:\nKiểm tra Metrics của các Worker Nodes Sau khi hoàn tất tạo Dashboard, ta sẽ thu thập được system metrics của các Worker Node như hình bên dưới. Worker Nodes trong K8s Cluster của chúng ta là 3 EC2 Instance nằm ở private subnet với địa chỉ IP như bên dưới:\nEC2 (1) với private IP là 10.0.4.56 EC2 (2) với private IP là 10.0.5.114 EC2 (3) với private IP là 10.0.6.202 "
},
{
	"uri": "//localhost:1313/vi/2-vpc-ec2/2.2-jump-jenkins-sonar/2.2.1-key/",
	"title": "Tạo cặp Public và Private Key ở Local Machine",
	"tags": [],
	"description": "",
	"content": "Tạo Public và Private Key ở local machine Sử dụng ssh-keygen để tạo một cặp public và private key. Đặt tên chúng là EC2.\nssh-keygen -b 2048 -t rsa Bạn đọc cần thêm cặp key pair này vào file .gitignore\nTạo file Terraform/04-keypair.tf với cấu hình bên dưới:\n## Key pair resource \u0026#34;aws_key_pair\u0026#34; \u0026#34;EC2key\u0026#34; { key_name = var.ec2_key_name public_key = file(\u0026#34;${path.module}/EC2.pub\u0026#34;) } "
},
{
	"uri": "//localhost:1313/vi/3-eks/3.1-eks-role/",
	"title": "Tạo Role cho EKS Cluster",
	"tags": [],
	"description": "",
	"content": "Tạo file Terraform/06-eks_role.tf như bên dưới:\nresource \u0026#34;aws_iam_role\u0026#34; \u0026#34;ekse_role\u0026#34; { name = \u0026#34;eks-cluster\u0026#34; assume_role_policy = \u0026lt;\u0026lt;POLICY { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Service\u0026#34;: \u0026#34;eks.amazonaws.com\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRole\u0026#34; } ] } POLICY } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;AmazonEKSClusterPolicy\u0026#34; { policy_arn = \u0026#34;arn:aws:iam::aws:policy/AmazonEKSClusterPolicy\u0026#34; role = aws_iam_role.ekse_role.name } "
},
{
	"uri": "//localhost:1313/vi/2-vpc-ec2/2.1-vpc/2.1.1-createvpc/",
	"title": "Tạo VPC, Internet Gateway, và NAT Gateway",
	"tags": [],
	"description": "",
	"content": "Tạo Folder Terraform, tạo các file Terraform/terraform.tfvars và Terraform/variables.tf. Các file này sẽ định nghĩa các cấu hình hạ tầng của ta.\nBạn đọc tham khảo tại đây Terraform/terraform.tfvars và Terraform/variables.tf\nTạo file Terraform/00-main.tf để định nghĩa AWS Provider.\nterraform { required_providers { aws = { source = \u0026#34;hashicorp/aws\u0026#34; version = \u0026#34;~\u0026gt; 5.0\u0026#34; } } required_version = \u0026#34;\u0026gt;= 1.2.0\u0026#34; } provider \u0026#34;aws\u0026#34; { region = \u0026#34;us-east-1\u0026#34; } Tạo VPC, Internet Gateway, và NAT Gateway Tạo file Terraform/01-vpc.tf để tạo VPC, Internet Gateway, và NAT Gateway.\nresource \u0026#34;aws_vpc\u0026#34; \u0026#34;main\u0026#34; { cidr_block = var.vpc_cidr enable_dns_hostnames = true enable_dns_support = true tags = { Name = var.vpc_name } } resource \u0026#34;aws_internet_gateway\u0026#34; \u0026#34;defaultIGW\u0026#34; { vpc_id = aws_vpc.main.id tags = { Name = \u0026#34;Internet Gateway\u0026#34; } } resource \u0026#34;aws_eip\u0026#34; \u0026#34;my_elastic_ip\u0026#34; { domain = \u0026#34;vpc\u0026#34; } # NAT Gateway resource \u0026#34;aws_nat_gateway\u0026#34; \u0026#34;my_nat_gtw\u0026#34; { allocation_id = aws_eip.my_elastic_ip.id subnet_id = values(aws_subnet.public_subnets)[0].id tags = { Name = \u0026#34;NAT Gateway\u0026#34; } } Như trên, ta cần tạo một Elastic IP Address và gán nó vào NAT Gateway của ta.\n"
},
{
	"uri": "//localhost:1313/vi/8-cicd-test/8.1-change-code/",
	"title": "Thay đổi Source Code ở Dev Repository",
	"tags": [],
	"description": "",
	"content": "Tại Local Dev Repository, thực hiện thay đổi Service API Gateway như hình bên dưới:\nSau đó, push lên Remote Repository. Ta sẽ có commit ID mới nhất như hình bên dưới:\nKiểm tra ở Registry, ta sẽ có image mới nhất như hình bên dưới:\n"
},
{
	"uri": "//localhost:1313/vi/4-cicd/4.1-application/",
	"title": "Tổng quan Application",
	"tags": [],
	"description": "",
	"content": "Application của chúng ta là được triển khai theo kiến trúc Microservices với 3 Services chính:\nService API Gateway: Sẽ là nguồn nhận traffic (đến từ user) và chịu trách nhiệm điều hướng Order Service: Chịu trách nhiệm Write Database Info Service: Chịu trách nhiệm Read Database Tổng cộng ta sẽ có 3 API Endpoints:\ndomain.com/ domain.com/create-order domain.com/get-orders Traffic từ User sẽ luôn đi đến Customer API Gateway (là Load Balancer hoặc một Reverse Proxy) và được điều hướng đến Service API Gateway. Bên dưới là minh hoạ các luồng traffic cho 3 API Endpoints.\n"
},
{
	"uri": "//localhost:1313/vi/",
	"title": "Triển khai DevSecOps và ứng dụng GitOps trong CI/CD Pipeline cho ứng dụng Microservices trên AWS EKS",
	"tags": [],
	"description": "",
	"content": "Triển khai DevSecOps và ứng dụng GitOps trong CI/CD Pipeline cho ứng dụng Microservices trên AWS EKS Tổng quan Trong bài Workshop này, bạn đọc sẽ tìm hiểu cách thức tích hợp DevSecOps và ứng dụng GitOps vào CI/CD Pipeline cho một ứng dụng Microservice được triển khai trên Amazon Elastic Kubernetes (EKS). Bạn đọc sẽ bắt đầu việc triển khai hạ tầng trên AWS bằng Terraform, triển khai CI/CD Pipeline, và cuối cùng tích hợp các phương pháp bảo mật trong DevOps, hay còn gọi là DevSecOps.\nKỳ vọng Kiến trúc hạ tầng Cloud Bên dưới là toàn bộ kiến trúc cho hạ tầng của chúng ta và các luồng traffic sau khi hoàn thành bài Workshop này\nCI Pipeline CI Pipeline được mô tả như hình bên dưới\nCD Pipeline CD Pipeline được mô tả như hình bên dưới\nToàn bộ Source Code cho Workshop này, bạn đọc có thể tham khảo:\nDev Repo (Nơi Dev Team sẽ làm việc): Link Ops Repo (Nơi Ops Team sẽ làm việc): Link Nội dung Đặt vấn đề Triển khai VPC, Jenkins, và SonarQube Server Triển khai Kubernetes Cluster Triển khai CI/CD Pipeline Triển khai DevSecOps Kiểm thử Dọn dẹp tài nguyên Tại mỗi phần, bạn đọc sẽ được hướng dẫn nên để Source Code ở Dev Repo hoặc Ops Repo\n"
},
{
	"uri": "//localhost:1313/vi/2-vpc-ec2/2.1-vpc/",
	"title": "Triển khai VPC",
	"tags": [],
	"description": "",
	"content": "Nội dung Tạo VPC, Internet Gateway, và NAT Gateway Tạo Subnet và Subnet Association Chạy Terraform để triển khai hạ tầng Sau khi hoàn thành phần này, hình bên dưới sẽ là hạ tầng của chúng ta:\n"
},
{
	"uri": "//localhost:1313/vi/7-argocd-autodeploy/7.2-ops-repo-update/",
	"title": "Cập nhật Ops Repository",
	"tags": [],
	"description": "",
	"content": "Ở file k8s/deployment.yaml ở Ops Repository, với các Image mà ta có ở Registry, cập nhật image cho từng Service và đẩy lên Remote Ops Repository như bên dưới:\nService API Gateway Info Service Order Service "
},
{
	"uri": "//localhost:1313/vi/4-cicd/4.2-jenkins/",
	"title": "Cấu hình Jenkins Server",
	"tags": [],
	"description": "",
	"content": "Cài đặt các Plugins và Tools cần thiết Truy cập Jenkins Server thông qua Domain Name của Jenkins Server EC2, ta sẽ được yêu cầu nhập Initial Password. Kết nối đến Jenkins Server thông qua giao thức SSH và thực hiện câu lệnh sau để lấy Initial Password:\nsudo cat /var/lib/jenkins/secrets/initialAdminPassword Thực hiện cài đặt các Suggested Plugins như hình dưới:\nTạo admin user như hình dưới:\nTại phần Dashboard \u0026gt; Manage Jenkins \u0026gt; Plugins, cài đặt các Plugins ở bên dưới:\nDocker Pipeline Amazon ECR SonarQube Scanner Tại phần Dashboard \u0026gt; Manage Jenkins \u0026gt; Tools, cài đặt SonarQube Scanner như hình bên dưới:\nThiết Lập Credentials Tại phần: Dashboard \u0026gt; Manage Jenkins \u0026gt; Credentials \u0026gt; System \u0026gt; Global credentials (unrestricted), tạo các credentials như hình bên dưới, trong đó:\náocd ácdc ácd cálc Thiết lập các CI Pipelines Thiết lập Pipeline cho Service API Gateway như hình bên dưới:\nTại phần Build Triggers, chọn GitHub hook trigger for GITScm polling như hình dưới:\nTại phần Pipeline, sửa như cấu hình bên dưới để kết nối đến GitHub Repository. Vì hiện tại Repository đang ở public, nên ta sẽ bỏ qua phần Credentials.\nThiết lập Branch main như hình bên dưới. Pipeline chỉ chạy khi có bất kỳ sự thay đổi nào ở branch main.\nỞ phần Script Path, sửa thành api-gateway/Jenkinsfile như hình dưới. Mỗi lần folder api-gateway thay đổi, Jenkins Server sẽ dựa vào file api-gateway/Jenkinsfile để bắt đầu chạy Pipeline.\nThiết lập Pipeline cho Info Service và Order Service cũng sẽ tương tự như trên. Tuy nhiên, tại phần Script Path ta sẽ thay đổi lần lượt thành info/Jenkinsfile và order/Jenkinsfile.\n"
},
{
	"uri": "//localhost:1313/vi/6-devsecops/6.2-sonar/",
	"title": "Cấu hình SonarQube Server",
	"tags": [],
	"description": "",
	"content": "Đăng nhập vào SonarQube Server Truy cập SonarQube Server thông qua EC2 DNS, bạn đọc đăng nhập vào SonarQube Server với tài khoản và mật khẩu là admin như hình bên dưới:\nTạo Local Project Tạo Local Project như hình bên dưới:\nĐặt tên Local Project là microservice như bên dưới:\nThiết lập Sonar File ở Dev Repository Tại Dev Repository, tạo file sonar-project.properties như bên dưới:\nsonar.projectKey=microservice Tạo Token để truy cập SonarQube Server Tại mục Administration \u0026gt; Security \u0026gt; Users, với user admin, tạo một Token cho Admin như hình bên dưới.\nĐây không phải là Best Practice vì chúng ta đang trao quyền admin cho Jenkins Server.\n"
},
{
	"uri": "//localhost:1313/vi/8-cicd-test/8.2-ci-sec/",
	"title": "Kiểm tra DevSecOps Pipeline (CI)",
	"tags": [],
	"description": "",
	"content": "SAST (Static Application Security Testing) Tại Jenkins Server, ta thấy trong Pipeline của ta có phần SonarQube Analysis Source Code như bên dưới:\nKiểm tra tại Sonar Server, ta sẽ có được kết quả sau khi Scan Source Code. Vulnerabilities không nhiều vì Application của ta khá đơn giản:\nBên dưới là các kết quả khác:\nImage Scan Tại Jenkins Server, ta thấy trong Pipeline của ta có phần Scan Image như bên dưới:\nBên dưới là kết quả sau khi scan Built Image và Source Code Terraform:\n"
},
{
	"uri": "//localhost:1313/vi/5-finish-monitoring/5.2-efk/",
	"title": "Set up EFK Stack",
	"tags": [],
	"description": "",
	"content": "Truy cập vào Kibana thông qua DNS Thông qua DNS ở phần EC2 \u0026gt; Load Balancers, bạn đọc truy cập Kibana và chọn Explore on my own như bên dưới:\nSet up Index Pattern Tại phần Management \u0026gt; Index Patterns \u0026gt; Create Index Pattern, tạo cấu hình như bên dưới:\nKiểm tra Kibana Quay lại trang chủ của Kibana, ta sẽ thu thập được toàn bộ Logs như hình bên dưới:\n"
},
{
	"uri": "//localhost:1313/vi/2-vpc-ec2/2.2-jump-jenkins-sonar/2.2.2-jump-host/",
	"title": "Tạo Jump Host",
	"tags": [],
	"description": "",
	"content": "Thông qua Jump Host, ta sẽ tương tác với cụm K8s, điều này sẽ giảm nguy cơ cụm K8s của ta có thể được public accessed. Dùng private key mà ta đã tạo ở phần trước để truy cập Jump Host thông qua giao thức SSH. Nhưng trước hết, ta cần cài đặt các package cần thiết thông qua file Bash Script. Tạo file Terraform/jump_host_install.sh như bên dưới:\n#!/bin/bash sudo apt update -y # Install eksctl ARCH=amd64 PLATFORM=$(uname -s)_$ARCH curl -sLO \u0026#34;https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_$PLATFORM.tar.gz\u0026#34; # (Optional) Verify checksum curl -sL \u0026#34;https://github.com/eksctl-io/eksctl/releases/latest/download/eksctl_checksums.txt\u0026#34; | grep $PLATFORM | sha256sum --check sudo tar -xzf eksctl_$PLATFORM.tar.gz -C /tmp \u0026amp;\u0026amp; rm eksctl_$PLATFORM.tar.gz sudo mv /tmp/eksctl /usr/local/bin # Install kubectl curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl.sha256\u0026#34; sudo install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl # install aws-cli sudo apt install -y unzip curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install --bin-dir /usr/local/bin --install-dir /usr/local/aws-cli --update # install docker sudo apt-get install -y ca-certificates curl sudo install -m 0755 -d /etc/apt/keyrings sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc sudo chmod a+r /etc/apt/keyrings/docker.asc echo \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\ $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin sudo curl -fsSL -o get_helm.sh https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 sudo chmod 700 get_helm.sh sudo bash get_helm.sh Vì phiên bản Jump Host hiện tại là Ubuntu 22.04, nếu bạn đọc có nhu cầu dùng khác bản 0S (Amazon Linux, etc.), bạn đọc cần cấu hình lại file Bash Script ở trên.\nKế tiếp, ta sẽ thiết lập cấu hình cho Jump Host. Tạo file Terraform/05-jump_host.tf như bên dưới:\n# Security Group for EC2 resource \u0026#34;aws_security_group\u0026#34; \u0026#34;JUMP_HOST_SG\u0026#34; { name = \u0026#34;JUMP_HOST_SG\u0026#34; description = \u0026#34;Allow SSH inbound and all outbound traffic\u0026#34; vpc_id = aws_vpc.main.id ingress = [ { from_port = -1 to_port = -1 protocol = \u0026#34;icmp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;], description = \u0026#34;Allow inbound ICMP Traffic\u0026#34; ipv6_cidr_blocks = [] prefix_list_ids = [] security_groups = [] self = false }, { from_port = 22 to_port = 22 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] description = \u0026#34;Allow inbound traffic on port 22\u0026#34; ipv6_cidr_blocks = [] prefix_list_ids = [] security_groups = [] self = false } ] egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } tags = { Name = \u0026#34;JUMP_HOST SG\u0026#34; } } resource \u0026#34;aws_instance\u0026#34; \u0026#34;Jump_host\u0026#34; { ami = var.ec2_ami instance_type = var.ec2_instance_type key_name = aws_key_pair.EC2key.key_name monitoring = true subnet_id = values(aws_subnet.public_subnets)[0].id vpc_security_group_ids = [aws_security_group.JUMP_HOST_SG.id] associate_public_ip_address = true user_data = file(\u0026#34;${path.module}/jump_host_install.sh\u0026#34;) tags = { Terraform = \u0026#34;true\u0026#34; Environment = \u0026#34;dev\u0026#34; Name = \u0026#34;Jump Host\u0026#34; } root_block_device { volume_size = 30 } } "
},
{
	"uri": "//localhost:1313/vi/2-vpc-ec2/2.2-jump-jenkins-sonar/",
	"title": "Tạo Jump Host, Jenkins, và Sonarqube Server",
	"tags": [],
	"description": "",
	"content": "Nội dung Tạo cặp Public và Private Key ở Local Machine Tạo Jump Host Tạo Jenkins Server Tạo SonarQube Server Chạy Terraform để triển khai hạ tầng Sau khi hoàn thành phần này, hình bên dưới sẽ là hạ tầng của chúng ta:\n"
},
{
	"uri": "//localhost:1313/vi/3-eks/3.2-eks-worker-role/",
	"title": "Tạo Role cho EKS Worker Node",
	"tags": [],
	"description": "",
	"content": "Tạo File Terraform/07-eks_roles_worker.tf như bên dưới:\nresource \u0026#34;aws_iam_role\u0026#34; \u0026#34;nodes\u0026#34; { name = \u0026#34;eks-node-group-nodes\u0026#34; assume_role_policy = jsonencode({ Statement = [{ Action = \u0026#34;sts:AssumeRole\u0026#34; Effect = \u0026#34;Allow\u0026#34; Principal = { Service = \u0026#34;ec2.amazonaws.com\u0026#34; } }] Version = \u0026#34;2012-10-17\u0026#34; }) } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;nodes_AmazonEKSWorkerNodePolicy\u0026#34; { policy_arn = \u0026#34;arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy\u0026#34; role = aws_iam_role.nodes.name } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;nodes_AmazonEKS_CNI_Policy\u0026#34; { policy_arn = \u0026#34;arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy\u0026#34; role = aws_iam_role.nodes.name } resource \u0026#34;aws_iam_role_policy_attachment\u0026#34; \u0026#34;nodes_AmazonEC2ContainerRegistryReadOnly\u0026#34; { policy_arn = \u0026#34;arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly\u0026#34; role = aws_iam_role.nodes.name } "
},
{
	"uri": "//localhost:1313/vi/2-vpc-ec2/2.1-vpc/2.1.2-create-subnet/",
	"title": "Tạo Subnet và Subnet Association",
	"tags": [],
	"description": "",
	"content": "Tạo Subnet Tạo file Terraform/02-subnet.tf để tạo subnet như bên dưới:\n// Public Subnet resource \u0026#34;aws_subnet\u0026#34; \u0026#34;public_subnets\u0026#34; { for_each = toset(var.vpc_public_subnets) vpc_id = aws_vpc.main.id cidr_block = each.value availability_zone = var.vpc_azs[index(var.vpc_public_subnets, each.value)] map_public_ip_on_launch = true tags = { Name = \u0026#34;Public Subnet ${index(var.vpc_public_subnets, each.value) + 1}\u0026#34; } } // Private Subnet resource \u0026#34;aws_subnet\u0026#34; \u0026#34;private_subnets\u0026#34; { for_each = toset(var.vpc_private_subnets) vpc_id = aws_vpc.main.id cidr_block = each.value availability_zone = var.vpc_azs[index(var.vpc_private_subnets, each.value)] tags = { Name = \u0026#34;Private Subnet ${index(var.vpc_private_subnets, each.value) + 1}\u0026#34; } } Route Table và Subnet Association Kế tiếp, ta sẽ tạo các Route Table, đồng thời associate Internet Gateway, NAT Gateway, và các Subnets. Tạo File Terraform/03-route_table.tf như bên dưới:\n// create public route table resource \u0026#34;aws_route_table\u0026#34; \u0026#34;public_route_table\u0026#34; { vpc_id = aws_vpc.main.id route { cidr_block = var.vpc_cidr gateway_id = \u0026#34;local\u0026#34; } route { cidr_block = \u0026#34;0.0.0.0/0\u0026#34; gateway_id = aws_internet_gateway.defaultIGW.id } tags = { Name = \u0026#34;Public Route Table\u0026#34; } } // create private route table resource \u0026#34;aws_route_table\u0026#34; \u0026#34;private_route_table\u0026#34; { vpc_id = aws_vpc.main.id tags = { Name = \u0026#34;Private Route Table\u0026#34; } } ## public subnet Association resource \u0026#34;aws_route_table_association\u0026#34; \u0026#34;public_subnets_associations\u0026#34; { for_each = aws_subnet.public_subnets subnet_id = each.value.id route_table_id = aws_route_table.public_route_table.id } ## private subnet Association resource \u0026#34;aws_route_table_association\u0026#34; \u0026#34;private_subnets_associations\u0026#34; { for_each = aws_subnet.private_subnets subnet_id = each.value.id route_table_id = aws_route_table.private_route_table.id } resource \u0026#34;aws_route\u0026#34; \u0026#34;route_nat_gw\u0026#34; { route_table_id = aws_route_table.private_route_table.id destination_cidr_block = \u0026#34;0.0.0.0/0\u0026#34; nat_gateway_id = aws_nat_gateway.my_nat_gtw.id timeouts { create = \u0026#34;5m\u0026#34; } } "
},
{
	"uri": "//localhost:1313/vi/2-vpc-ec2/",
	"title": "Triển khai VPC, Jenkins, và SonarQube Server",
	"tags": [],
	"description": "",
	"content": "\rSource code tại phần này sẽ được triển khai tại Ops Repo\nTrong phần này, chúng ta sẽ triển khai một VPC với:\n3 Availability Zones 3 Public Subnets 3 Private Subnets 1 Internet Gateway 1 NAT Gateway 3 EC2, trong đó: 1 Jump Host để tương tác với cụm K8s ở private subnet 1 Jenkins Server để triển khai CI pipeline 1 SonarQube Server trong quy trình DevSecOps Nội dung Triển khai VPC Tạo Jump Host, Jenkins Server, và SonarQube Server "
},
{
	"uri": "//localhost:1313/vi/7-argocd-autodeploy/7.3-argocd/",
	"title": "Auto Deployment với Argo CD",
	"tags": [],
	"description": "",
	"content": "Tại mục EC2 \u0026gt; Load Balancers, dùng DNS của Argo CD để truy cập đến trang web của Argo CD. Bạn đọc sẽ được yêu cầu đăng nhập với tài khoản là admin và Initial Password. Để lấy được Initial Password của Argo CD, bạn đọc thực hiện câu lệnh sau tại Jump Host (hãy chắc chắn rằng Jump Host có credentials để tương tác với K8s Cluster):\nkubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\u0026#34;{.data.password}\u0026#34; | base64 -d Kết nối đến Ops Repository Sau khi đăng nhập, tại phần Settings \u0026gt; Repositories, kết nối đến Ops Repository với cấu hình bên dưới:\nApplication Deployment Tại phần Applications, tạo một application mới với cấu hình bên dưới:\nKiểm tra Sau khi Create Application, Argo CD sẽ tự động deploy các application pods vào K8s Cluster của ta như hình bên dưới:\nTrở lại AWS Console Management, tại phần EC2 \u0026gt; Load Balancers, ta sẽ thấy có một Load Balancer mới được deployed (trước đó chỉ có 3 Load Balancers), đó chính là đường dẫn đến Production của ta.\n"
},
{
	"uri": "//localhost:1313/vi/4-cicd/4.3-dev-repo/",
	"title": "Cấu hình GitHub Repository (Dev Repo)",
	"tags": [],
	"description": "",
	"content": "Thiết lập Webhook Tại phần Settings -\u0026gt; Webhooks ở Dev Repository, chọn phần \u0026lsquo;Add Webhooks’ với setting ở bên dưới:\nViết Jenkins File Bài Workshop này sẽ không hướng dẫn viết Jenkinsfile, bạn đọc tham khảo tại Dev Repo.\n"
},
{
	"uri": "//localhost:1313/vi/6-devsecops/6.3-jenkins/",
	"title": "Cấu hình Jenkins Server",
	"tags": [],
	"description": "",
	"content": "Thiết lập SonarQube Server Quay trở về Jenkins Server, tại phần Credentials, thêm vào một credential cho Sonar với Token mà ta lấy được ở phần trước. Tạo một credential như hình dưới:\nTại phần Dashboard \u0026gt; Manage Jenkins \u0026gt; System, ở mục SonarQube servers, thêm vào cấu hình bên dưới:\nTạo Ops Pipeline Tạo Ops Pipeline tương tự như Service API Gateway Pipeline, tuy nhiên, GitHub Repository sẽ là URL dẫn đến remote Ops Repo.\n"
},
{
	"uri": "//localhost:1313/vi/2-vpc-ec2/2.1-vpc/2.1.3-run-terraform/",
	"title": "Chạy Terraform để triển khai hạ tầng",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/3-eks/3.3-eks-create/",
	"title": "Tạo EKS Cluster",
	"tags": [],
	"description": "",
	"content": "Tạo File Terraform/08-eks.tf như bên dưới:\nmodule \u0026#34;eks\u0026#34; { source = \u0026#34;terraform-aws-modules/eks/aws\u0026#34; cluster_name = var.cluster_name cluster_version = var.cluster_version vpc_id = aws_vpc.main.id subnet_ids = [for subnet in aws_subnet.private_subnets : subnet.id] cluster_endpoint_public_access = true iam_role_arn = aws_iam_role.ekse_role.arn enable_cluster_creator_admin_permissions = true cluster_addons = { kube-proxy = { most_recent = true } vpc-cni = { most_recent = true } } control_plane_subnet_ids = [for subnet in aws_subnet.private_subnets : subnet.id] tags = { Environment = \u0026#34;Development\u0026#34; } depends_on = [aws_iam_role_policy_attachment.AmazonEKSClusterPolicy] } "
},
{
	"uri": "//localhost:1313/vi/2-vpc-ec2/2.2-jump-jenkins-sonar/2.2.3-jenkins/",
	"title": "Tạo Jenkins Server",
	"tags": [],
	"description": "",
	"content": "Jenkins Server sẽ là nơi thực hiện hầu hết các Pipeline của chúng ta: CI Pipeline và Pipeline cho DevSecOps. Mỗi lần có một commit mới ở Dev Repo hoặc Ops Repo, Jenkins sẽ tự động chạy các pipeline dựa vào cách mà ta cấu hình.\nTạo File Terraform/jenkins_install.sh như bên dưới để cài đặt các package cần thiết cho Jenkins Server.\n#!/bin/bash sudo apt update -y # install docker sudo apt-get install -y ca-certificates curl sudo install -m 0755 -d /etc/apt/keyrings sudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc sudo chmod a+r /etc/apt/keyrings/docker.asc echo \\ \u0026#34;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\ $(. /etc/os-release \u0026amp;\u0026amp; echo \u0026#34;$VERSION_CODENAME\u0026#34;) stable\u0026#34; | \\ sudo tee /etc/apt/sources.list.d/docker.list \u0026gt; /dev/null sudo apt-get update sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin # install aws-cli sudo apt install -y unzip curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install --bin-dir /usr/local/bin --install-dir /usr/local/aws-cli --update # install java and jenkins sudo apt install -y fontconfig openjdk-17-jre sudo wget -O /usr/share/keyrings/jenkins-keyring.asc \\ https://pkg.jenkins.io/debian-stable/jenkins.io-2023.key echo \u0026#34;deb [signed-by=/usr/share/keyrings/jenkins-keyring.asc]\u0026#34; \\ https://pkg.jenkins.io/debian-stable binary/ | sudo tee \\ /etc/apt/sources.list.d/jenkins.list \u0026gt; /dev/null sudo apt-get update sudo apt-get install -y jenkins sudo systemctl start jenkins # install nginx sudo apt install -y nginx sudo systemctl start nginx sudo rm /etc/nginx/sites-enabled/default sudo tee /etc/nginx/sites-enabled/default \u0026gt; /dev/null \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; server { listen 80; server_name _; location / { proxy_pass http://localhost:8080; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_redirect off; } } EOF sudo systemctl reload nginx sudo usermod -aG docker jenkins sudo systemctl restart jenkins sudo systemctl restart docker sudo apt-get install -y wget apt-transport-https gnupg wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | gpg --dearmor | sudo tee /usr/share/keyrings/trivy.gpg \u0026gt; /dev/null echo \u0026#34;deb [signed-by=/usr/share/keyrings/trivy.gpg] https://aquasecurity.github.io/trivy-repo/deb generic main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/trivy.list sudo apt-get update sudo apt-get install -y trivy # Install OWASP ZAP docker pull zaproxy/zap-stable Kế tiếp, ta sẽ thiết lập cấu hình cho Jenkins Server. Tạo file Terraform/05-jenkins_server.tf như bên dưới:\n# Security Group for EC2\rresource \u0026#34;aws_security_group\u0026#34; \u0026#34;JENKINS_SG\u0026#34; {\rname = \u0026#34;JENKINS_SG\u0026#34;\rdescription = \u0026#34;Allow HTTP inbound and all outbound traffic\u0026#34;\rvpc_id = aws_vpc.main.id\ringress = [\r{\rfrom_port = 80\rto_port = 80\rprotocol = \u0026#34;tcp\u0026#34;\rcidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;]\rdescription = \u0026#34;Allow inbound traffic on port 80\u0026#34;\ripv6_cidr_blocks = []\rprefix_list_ids = []\rsecurity_groups = []\rself = false\r},\r{\rfrom_port = -1\rto_port = -1\rprotocol = \u0026#34;icmp\u0026#34;\rcidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;],\rdescription = \u0026#34;Allow inbound ICMP Traffic\u0026#34;\ripv6_cidr_blocks = []\rprefix_list_ids = []\rsecurity_groups = []\rself = false\r},\r{\rfrom_port = 22\rto_port = 22\rprotocol = \u0026#34;tcp\u0026#34;\rcidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;]\rdescription = \u0026#34;Allow inbound traffic on port 22\u0026#34;\ripv6_cidr_blocks = []\rprefix_list_ids = []\rsecurity_groups = []\rself = false\r}\r]\regress {\rfrom_port = 0\rto_port = 0\rprotocol = \u0026#34;-1\u0026#34;\rcidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;]\r}\rtags = {\rName = \u0026#34;Jenkins Server SG\u0026#34;\r}\r}\rresource \u0026#34;aws_instance\u0026#34; \u0026#34;Jenkins_server\u0026#34; {\rami = var.ec2_ami\rinstance_type = var.ec2_instance_type\rkey_name = aws_key_pair.EC2key.key_name\rmonitoring = true\rsubnet_id = values(aws_subnet.public_subnets)[2].id\rvpc_security_group_ids = [aws_security_group.JENKINS_SG.id]\rassociate_public_ip_address = true\ruser_data = file(\u0026#34;${path.module}/jenkins_install.sh\u0026#34;)\rtags = {\rTerraform = \u0026#34;true\u0026#34;\rEnvironment = \u0026#34;dev\u0026#34;\rName = \u0026#34;Jenkins Server\u0026#34;\r}\rroot_block_device {\rvolume_size = 30\r}\r} "
},
{
	"uri": "//localhost:1313/vi/8-cicd-test/8.3-change-code-ops/",
	"title": "Thay đổi Source Code ở Ops Repo",
	"tags": [],
	"description": "",
	"content": "Bạn đọc tham khảo Ops Repository tại đây. Tại Jenkinsfile, chỉnh sửa PRODUCTION_LINK như bên dưới. Đây sẽ là đường liên kết để OWASP ZAP tiến hành kiểm tra lỗ hổng bảo mật.\nTại file k8s/deployment.yaml, sửa image của API Gateway như hình bên dưới:\nĐẩy source code lên Remote Github Repository để chạy DevSecOps Pipeline và Argo CD Auto Application Update.\n"
},
{
	"uri": "//localhost:1313/vi/3-eks/",
	"title": "Triển khai Kubernetes Cluster",
	"tags": [],
	"description": "",
	"content": "\rSource code tại phần này sẽ được triển khai tại Ops Repo\nTại phần này, ta sẽ triển khai cụm Kubernetes Cluster, cũng chính là nơi mà application sẽ được deployed. Thêm vào đó, ta cũng sẽ tạo Elastic Container Registry, nơi đây sẽ chứa các built image của chúng ta.\nKết thúc phần này, ta sẽ có hoàn chỉnh phần Infrastructure, việc còn lại là triển khai CI/CD Pipeline và DevSecOps. Hình bên dưới sẽ là hạ tầng của chúng ta sau khi hoàn thành phần này.\nNội dung Tạo Role cho EKS Cluster Tạo Role cho EKS Worker Node Tạo EKS Cluster Tạo EKS Worker Node Tạo Elastic Container Registry Chạy Terraform để triển khai hạ tầng "
},
{
	"uri": "//localhost:1313/vi/4-cicd/4.4-argocd-autodeploy/",
	"title": "Cấu hình Argo CD",
	"tags": [],
	"description": "",
	"content": "\rSource code tại phần này sẽ được triển khai tại Ops Repo\nTại Ops Repository, tạo Folder argocd với các files tại đây. Sơ qua, với các File như hình dưới, Argo CD sẽ đựơc deployed trong namespace argocd:\n"
},
{
	"uri": "//localhost:1313/vi/6-devsecops/6.4-trivy-owasp-zap/",
	"title": "Cấu hình Trivy và OWASP ZAP",
	"tags": [],
	"description": "",
	"content": "Trivy và OWASP ZAP đã được cài đặt ở Jenkins Server, thông qua file Terraform/jenkins_install.sh ở Ops Repository, bạn đọc có thể thấy chúng đã được cài đặt:\n... sudo apt-get install -y wget apt-transport-https gnupg wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | gpg --dearmor | sudo tee /usr/share/keyrings/trivy.gpg \u0026gt; /dev/null echo \u0026#34;deb [signed-by=/usr/share/keyrings/trivy.gpg] https://aquasecurity.github.io/trivy-repo/deb generic main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/trivy.list sudo apt-get update sudo apt-get install -y trivy # Install OWASP ZAP docker pull zaproxy/zap-stable "
},
{
	"uri": "//localhost:1313/vi/4-cicd/",
	"title": "Chuẩn bị CI/CD Pipeline",
	"tags": [],
	"description": "",
	"content": "\rSource code tại phần này sẽ được triển khai tại Dev Repo và Ops Repo\nTại phần này, chúng ta sẽ hoàn thiện CI/CD Pipeline. Chúng ta sẽ tạo các Jenkinsfile và bắt đầu tương tác với cụm K8s.\nNội dung Tổng quan Application Cấu hình Jenkins Server Cấu hình GitHub Repository (Dev Repo) Cấu hình ArgoCD và Automation Deployment Cấu hình Prometheus và Grafana Cấu hình EFK Stack "
},
{
	"uri": "//localhost:1313/vi/8-cicd-test/8.4-cd-sec/",
	"title": "Kiểm tra DevSecOps Pipeline (CD)",
	"tags": [],
	"description": "",
	"content": "Tại Jenkins Server, Ops Pipeline sẽ được trigger để tiến hành scan Source Code Terraform và dùng OWASP ZAP để kiểm tra bảo mật cho Website của chúng ta.\nSecure IaC DAST (Dynamic Application Security Testing) "
},
{
	"uri": "//localhost:1313/vi/3-eks/3.4-eks-worker-node-create/",
	"title": "Tạo EKS Worker Node",
	"tags": [],
	"description": "",
	"content": "Tạo File Terraform/09-eks_worker_nodes.tf như bên dưới:\nresource \u0026#34;aws_eks_node_group\u0026#34; \u0026#34;my_nodes\u0026#34; { cluster_name = var.cluster_name node_group_name = \u0026#34;ClusterNode\u0026#34; node_role_arn = aws_iam_role.nodes.arn subnet_ids = [for subnet in aws_subnet.private_subnets : subnet.id] capacity_type = \u0026#34;ON_DEMAND\u0026#34; instance_types = [var.ec2_instance_type] scaling_config { desired_size = 3 max_size = 4 min_size = 2 } update_config { max_unavailable = 1 } labels = { role = \u0026#34;general\u0026#34; } depends_on = [ aws_iam_role_policy_attachment.nodes_AmazonEKSWorkerNodePolicy, aws_iam_role_policy_attachment.nodes_AmazonEKS_CNI_Policy, aws_iam_role_policy_attachment.nodes_AmazonEC2ContainerRegistryReadOnly, module.eks.cluster_id ] } "
},
{
	"uri": "//localhost:1313/vi/2-vpc-ec2/2.2-jump-jenkins-sonar/2.2.4-sonar/",
	"title": "Tạo SonarQube Server",
	"tags": [],
	"description": "",
	"content": "SonarQube Server sẽ có nhiệm vụ kiểm thử Source Code của chúng ta. Bạn đọc có thể cùng host cả Jenkins và Sonar Server trên cùng một EC2 để tiết kiệm chi phí. Với bài workshop này, tôi sẽ tách biệt cả hai thành 2 EC2. Tạo file Terraform/sonarqube_install.sh như bên dưới:\n#!/bin/bash sudo apt update -y sudo apt install -y fontconfig openjdk-17-jre # Sonarqube sudo apt install curl ca-certificates sudo install -d /usr/share/postgresql-common/pgdg sudo curl -o /usr/share/postgresql-common/pgdg/apt.postgresql.org.asc --fail https://www.postgresql.org/media/keys/ACCC4CF8.asc sudo sh -c \u0026#39;echo \u0026#34;deb [signed-by=/usr/share/postgresql-common/pgdg/apt.postgresql.org.asc] https://apt.postgresql.org/pub/repos/apt $(lsb_release -cs)-pgdg main\u0026#34; \u0026gt; /etc/apt/sources.list.d/pgdg.list\u0026#39; sudo apt update sudo apt install postgresql-15 -y sudo -i -u postgres bash \u0026lt;\u0026lt; EOF # Create the user and database, and set the password createuser sonar createdb sonar -O sonar psql -c \u0026#34;ALTER USER sonar WITH ENCRYPTED PASSWORD \u0026#39;your_password\u0026#39;;\u0026#34; EOF wget https://binaries.sonarsource.com/Distribution/sonarqube/sonarqube-10.5.1.90531.zip sudo apt install -y unzip sudo unzip sonarqube-10.5.1.90531.zip sudo mv sonarqube-10.5.1.90531 /opt/sonarqube sudo adduser --system --no-create-home --group --disabled-login sonarqube sudo chown -R sonarqube:sonarqube /opt/sonarqube sudo bash -c \u0026#39;cat \u0026lt;\u0026lt; EOF \u0026gt; /opt/sonarqube/conf/sonar.properties sonar.jdbc.username=sonar sonar.jdbc.password=your_password sonar.jdbc.url=jdbc:postgresql://localhost/sonar EOF\u0026#39; sudo bash -c \u0026#39;cat \u0026lt;\u0026lt; EOF \u0026gt; /etc/systemd/system/sonarqube.service [Unit] Description=SonarQube service After=syslog.target network.target [Service] Type=forking ExecStart=/opt/sonarqube/bin/linux-x86-64/sonar.sh start ExecStop=/opt/sonarqube/bin/linux-x86-64/sonar.sh stop User=sonarqube Group=sonarqube Restart=always LimitNOFILE=65536 LimitNPROC=4096 [Install] WantedBy=multi-user.target EOF\u0026#39; sudo systemctl daemon-reload sudo systemctl start sonarqube sudo systemctl enable sonarqube # Update limits.conf sudo bash -c \u0026#39;cat \u0026lt;\u0026lt; EOF \u0026gt;\u0026gt; /etc/security/limits.conf sonarqube - nofile 65536 sonarqube - nproc 4096 EOF\u0026#39; # Update sysctl.conf sudo bash -c \u0026#39;cat \u0026lt;\u0026lt; EOF \u0026gt;\u0026gt; /etc/sysctl.conf vm.max_map_count=262144 EOF\u0026#39; sudo sysctl -p # install nginx sudo apt install -y nginx sudo systemctl start nginx sudo rm /etc/nginx/sites-enabled/default sudo tee /etc/nginx/sites-enabled/default \u0026gt; /dev/null \u0026lt;\u0026lt; \u0026#39;EOF\u0026#39; server { listen 80; server_name _; location / { proxy_pass http://localhost:9000; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header Host $http_host; proxy_redirect off; } } EOF sudo systemctl reload nginx Kế tiếp, ta sẽ thiết lập cấu hình cho Sonar Server. Tạo file Terraform/05-sonar_server.tf như bên dưới:\n# Security Group for EC2 resource \u0026#34;aws_security_group\u0026#34; \u0026#34;SONAR_HOST_SG\u0026#34; { name = \u0026#34;SONAR_HOST_SG\u0026#34; description = \u0026#34;Allow SSH, HTTP inbound and all outbound traffic\u0026#34; vpc_id = aws_vpc.main.id ingress = [ { from_port = 80 to_port = 80 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] description = \u0026#34;Allow inbound traffic on port 80\u0026#34; ipv6_cidr_blocks = [] prefix_list_ids = [] security_groups = [] self = false }, { from_port = -1 to_port = -1 protocol = \u0026#34;icmp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;], description = \u0026#34;Allow inbound ICMP Traffic\u0026#34; ipv6_cidr_blocks = [] prefix_list_ids = [] security_groups = [] self = false }, { from_port = 22 to_port = 22 protocol = \u0026#34;tcp\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] description = \u0026#34;Allow inbound traffic on port 22\u0026#34; ipv6_cidr_blocks = [] prefix_list_ids = [] security_groups = [] self = false } ] egress { from_port = 0 to_port = 0 protocol = \u0026#34;-1\u0026#34; cidr_blocks = [\u0026#34;0.0.0.0/0\u0026#34;] } tags = { Name = \u0026#34;SONAR_HOST SG\u0026#34; } } resource \u0026#34;aws_instance\u0026#34; \u0026#34;Sonar_host\u0026#34; { ami = var.ec2_ami instance_type = var.ec2_instance_type key_name = aws_key_pair.EC2key.key_name monitoring = true subnet_id = values(aws_subnet.public_subnets)[1].id vpc_security_group_ids = [aws_security_group.SONAR_HOST_SG.id] associate_public_ip_address = true user_data = file(\u0026#34;${path.module}/sonarqube_install.sh\u0026#34;) tags = { Terraform = \u0026#34;true\u0026#34; Environment = \u0026#34;dev\u0026#34; Name = \u0026#34;Sonar Host\u0026#34; } root_block_device { volume_size = 30 } } "
},
{
	"uri": "//localhost:1313/vi/7-argocd-autodeploy/7.4-app-access/",
	"title": "Truy cập Application",
	"tags": [],
	"description": "",
	"content": "Truy cập Application Thông qua Load Balancer, truy cập Application của ta như hình bên dưới:\nThực hiện request đến Info Service, ta sẽ nhận được kết quả như bên dưới:\nDev Team Debug với EFK Stack Tại đường dẫn domain.com/get-orders, nếu thực hiện load nhiều lần, ta sẽ có lỗi như hình bên dưới:\nVấn đề đã xảy ra, chúng ta có bugs và cần fix sớm nhất có thể. Rất may là ta đã dùng EFK Stack để centralized các logs tại một nơi. Thông qua Kibana, Dev Team có thể biết được logs của các pods như bên dưới:\nĐây chính là do ta chưa implement các Queue để các Service giao tiếp với nhau khi chúng đang giao tiếp với cơ chế bất đồng bộ (asynchronous). Quả thật, triển khai một ứng dụng Microservices không hề dễ dàng.\n"
},
{
	"uri": "//localhost:1313/vi/4-cicd/4.5-prometheus-grafana/",
	"title": "Cấu hình Prometheus và Grafana",
	"tags": [],
	"description": "",
	"content": "\rSource code tại phần này sẽ được triển khai tại Ops Repo\nTại Ops Repository, tạo Folder monitoring với các files tại đây. Sơ qua, với các File như hình dưới, Grafana sẽ được sẽ được deployed trong namespace monitoring:\nTa sẽ triển khai Prometheus ở phần Bash Scripting, hiện tại, đây chỉ là những file cấu hình và chúng chưa được deploy lên K8s.\n"
},
{
	"uri": "//localhost:1313/vi/2-vpc-ec2/2.2-jump-jenkins-sonar/2.2.5-run-terraform/",
	"title": "Chạy Terraform để triển khai hạ tầng",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/5-finish-monitoring/",
	"title": "Hoàn thiện Monitoring",
	"tags": [],
	"description": "",
	"content": "\rSource code tại phần này sẽ được triển khai tại Dev Repo và Ops Repo\nTại phần này, chúng ta sẽ hoàn thiện CI/CD Pipeline. Chúng ta sẽ tạo các Jenkinsfile và bắt đầu tương tác với cụm K8s.\nNội dung Tổng quan Application Cấu hình Jenkins Server Cấu hình GitHub Repository (Dev Repo) Cấu hình ArgoCD và Automation Deployment Cấu hình Prometheus và Grafana Cấu hình EFK Stack "
},
{
	"uri": "//localhost:1313/vi/8-cicd-test/8.5-app/",
	"title": "Kiểm tra Application Auto Update",
	"tags": [],
	"description": "",
	"content": "Old Version Trước khi commit ở Ops Repository, bên dưới là application của ta:\nNew Version Tại Argo CD, ta có thể thấy API Gateway Pods đang được cập nhật như hình bên dưới:\nCuối cùng, tại trang Production của ta đã được cập nhật với phiên bản mới nhất:\n"
},
{
	"uri": "//localhost:1313/vi/3-eks/3.5-ecr/",
	"title": "Tạo Elastic Container Registry",
	"tags": [],
	"description": "",
	"content": "Tạo File Terraform/10-ecr như bên dưới:\nresource \u0026#34;aws_ecr_repository\u0026#34; \u0026#34;ECR\u0026#34; { name = \u0026#34;fcjws2\u0026#34; image_tag_mutability = \u0026#34;IMMUTABLE\u0026#34; image_scanning_configuration { scan_on_push = false } } "
},
{
	"uri": "//localhost:1313/vi/4-cicd/4.6-efk/",
	"title": "Cấu hình EFK Stack",
	"tags": [],
	"description": "",
	"content": "\rSource code tại phần này sẽ được triển khai tại Ops Repo\nTại Ops Repository, tạo Folder EFK với các files tại đây. Sơ qua, với các File như hình dưới, EFK Stack sẽ được sẽ được deployed trong namespace efklog:\n"
},
{
	"uri": "//localhost:1313/vi/3-eks/3.6-run-terraform/",
	"title": "Chạy Terraform để triển khai hạ tầng",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/6-devsecops/",
	"title": "Triển khai DevSecOps",
	"tags": [],
	"description": "",
	"content": "Dùng Terminal và trỏ vào thư mục chứa source code terraform ở trên. Thực hiện command line sau:\nterraform destroy Tất cả các tài nguyên sẽ được tự động dọn dẹp như hình bên dưới:\n"
},
{
	"uri": "//localhost:1313/vi/7-argocd-autodeploy/",
	"title": "Application Deployment",
	"tags": [],
	"description": "",
	"content": "terraform destroy Tất cả các tài nguyên sẽ được tự động dọn dẹp như hình bên dưới:\n"
},
{
	"uri": "//localhost:1313/vi/4-cicd/4.7-bashscript/",
	"title": "Bash Script cho Automation Deployment",
	"tags": [],
	"description": "",
	"content": "\rSource code tại phần này sẽ được triển khai tại Ops Repo\nChúng ta sẽ dùng bash script để tạo các stack Argo CD, Prometheus, Grafana, và EFK Stack. Tại Ops Repo, tạo file setup.sh như bên dưới.\n#!/bin/bash #set up argo cd kubectl apply -f argocd/namespace.yaml kubectl apply -f argocd/default.yaml -n argocd #set up efk stack kubectl apply -f EFK/. #set up Prometheus and Grafana kubectl create namespace monitoring helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo update helm install prometheus-operator prometheus-community/kube-prometheus-stack -n monitoring kubectl apply -f monitoring/grafana.yaml -n monitoring Bây giờ, Ops Repository của ta đã có hoàn chỉnh như hình:\nBây giờ, đẩy tất cả mọi thứ lên GitHub Repository với git push.\nFolder k8s sẽ không được đề cập ở đây, bạn đọc có thể tham khảo Source Code tại Ops Repository của tôi.\n"
},
{
	"uri": "//localhost:1313/vi/8-cicd-test/",
	"title": "Kiểm thử CI/CD Pipeline",
	"tags": [],
	"description": "",
	"content": "terraform destroy Tất cả các tài nguyên sẽ được tự động dọn dẹp như hình bên dưới:\n"
},
{
	"uri": "//localhost:1313/vi/4-cicd/4.8-k8s/",
	"title": "Triển khai K8s Cluster",
	"tags": [],
	"description": "",
	"content": "Kết nối đến Jump Host Dùng Console Management, tại phần EC2 \u0026gt; Security Group, ta cần sửa Security Group cho EKS Control Plane sao cho EKS Control Plane sẽ chấp nhận traffic đến từ Jump Host ở Port 443.\nBây giờ, dùng private key để kết nối đến Jump Host thông qua giao thức SSH. Sau đó, tại Jump Host, ta cần thiết lập AWS Credentials để có thể truy cập Cluster.\nDùng Environment Variables để đảm bảo rằng khi kết thúc phiên làm việc, AWS Credentials sẽ không còn lưu tại Jump Host\nexport AWS_ACCESS_KEY_ID=\u0026lt;your-access-id\u0026gt; \\ export AWS_SECRET_ACCESS_KEY=\u0026lt;your-secret\u0026gt; \\ export AWS_DEFAULT_REGION=\u0026lt;your-deployed-region\u0026gt; Sau đó, dùng AWS CLI để config EKS Cluster. Với bài Workshop này, EKS Cluster có tên là WS2Cluster và được deployed ở region us-east-1, thế nên, ta sẽ config như bên dưới:\naws eks update-kubeconfig --region us-east-1 --name WS2Cluster Triển khai K8s Cluster Dùng Git để clone Ops Repository về Jump Host như bên dưới (Bạn đọc tham khảo Ops Repository của tôi như bên dưới):\ngit clone https://github.com/heyyytamvo/FCJ2024-WS2-OpsRepo.git Bây giờ, ta sẽ triển khai Argo CD, Prometheus, Grafana, và EFK Stack với việc chạy file setup.sh như bên dưới:\ncd FCJ2024-WS2-OpsRepo\rchmod +x setup.sh\rsource setup.sh Nếu bạn đọc truy cập phần EC2 \u0026gt; Load Balancers, ta sẽ có tổng cộng 3 Load Balancers, mỗi DNS sẽ đưa ta đến:\nArgo CD Web Grafana Web Kibana Web "
},
{
	"uri": "//localhost:1313/vi/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "//localhost:1313/vi/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]